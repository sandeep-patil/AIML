{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Lasso Regression**\n",
        "\n",
        "Full Form: Least Absolute Shrinkage and Selection Operator.\n",
        "\n",
        "Lasso regressionâ€”also known as L1 regularizationâ€”is a form of regularization for linear regression models. Regularization\n",
        "\n",
        "**Goal**: Perform linear regression + feature selection by penalizing large coefficients.\n",
        "\n",
        "\n",
        "**Lasso helps you by:**\n",
        "\n",
        "Punishing unnecessary features\n",
        "\n",
        "Automatically dropping those that are not useful (by setting their contribution to zero)\n",
        "\n",
        "**Why Use Lasso in ML?**\n",
        "It avoids overthinking (overfitting) by keeping only whatâ€™s needed.\n",
        "\n",
        "It gives you a simpler model.\n",
        "\n",
        "Itâ€™s great when you have too many features and donâ€™t know which are important."
      ],
      "metadata": {
        "id": "1zlo5ivBgiAZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… **L1 Error â‰  Lasso Error**, but they are **related**.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ What is **L1 Error**?\n",
        "\n",
        "L1 error refers to the **sum of absolute differences**:\n",
        "\n",
        "$$\n",
        "\\text{L1 Error} = \\sum |y - \\hat{y}|\n",
        "$$\n",
        "\n",
        "This is used in **robust regression** (sometimes called **Least Absolute Deviations** regression).\n",
        "It focuses on minimizing **prediction errors** directly â€” itâ€™s an alternative to MSE (mean squared error).\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ”¹ What is **Lasso Error**?\n",
        "\n",
        "Lasso uses **L2 error** (squared error) **+** **L1 penalty** on the **coefficients**, not on the prediction error.\n",
        "\n",
        "$$\n",
        "\\text{Lasso Error} = \\sum (y - \\hat{y})^2 \\quad + \\quad \\alpha \\sum |w_i|\n",
        "$$\n",
        "\n",
        "âœ… So in Lasso:\n",
        "\n",
        "* The **error part** is based on squared differences (like Linear Regression).\n",
        "* The **penalty part** uses **L1 norm of coefficients** (absolute values of weights).\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ” Summary:\n",
        "\n",
        "| Term            | Applies To                            | Used In              |\n",
        "| --------------- | ------------------------------------- | -------------------- |\n",
        "| **L1 Error**    | Error between y and Å·                 | Robust Regression    |\n",
        "| **L1 Penalty**  | Applied to model weights $w$          | **Lasso Regression** |\n",
        "| **Lasso Error** | Squared prediction error + L1 penalty | Lasso Regression     |\n",
        "\n",
        "---\n",
        "\n",
        "ðŸ“Œ **Think of it this way**:\n",
        "\n",
        "> Lasso â‰  L1 error\n",
        "> But Lasso **uses the L1 norm** as a **penalty on model weights**, not on prediction error.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "AA08F0P-jU7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Maths Behind :**\n",
        "\n",
        "Letâ€™s walk through that **step by step** with a small numerical example (without any complex formulas).\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ Lasso = Linear Regression + Penalty on Weights\n",
        "\n",
        "The loss (total cost) in Lasso is:\n",
        "\n",
        "$$\n",
        "\\text{Lasso Loss} = \\text{Prediction Error} + \\text{Penalty}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”¢ Step-by-Step Example:\n",
        "\n",
        "Say we are predicting **student score** using 2 inputs:\n",
        "\n",
        "* $x_1$ = hours studied\n",
        "* $x_2$ = number of revisions\n",
        "\n",
        "And actual output:\n",
        "\n",
        "| xâ‚ | xâ‚‚ | y (actual marks) |\n",
        "| -- | -- | ---------------- |\n",
        "| 1  | 1  | 10               |\n",
        "\n",
        "Now assume some **trial weights** and **bias**:\n",
        "\n",
        "* $w_1 = 4$, $w_2 = 2$, $b = 1$\n",
        "\n",
        "### âž¤ Step 1: Predict using Linear Equation\n",
        "\n",
        "$$\n",
        "\\hat{y} = 4Ã—1 + 2Ã—1 + 1 = 7\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### âž¤ Step 2: Compute Squared Error\n",
        "\n",
        "$$\n",
        "\\text{Error} = (y - \\hat{y})^2 = (10 - 7)^2 = 9\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### âž¤ Step 3: Calculate Lasso Penalty (L1)\n",
        "\n",
        "Lasso adds this:\n",
        "\n",
        "$$\n",
        "\\text{Penalty} = \\alpha (|w_1| + |w_2|)\n",
        "$$\n",
        "\n",
        "Letâ€™s say $\\alpha = 1$\n",
        "\n",
        "$$\n",
        "\\text{Penalty} = 1 Ã— (|4| + |2|) = 6\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Step 4: Add Penalty to Total Loss\n",
        "\n",
        "$$\n",
        "\\text{Lasso Loss} = 9 (error) + 6 (penalty) = 15\n",
        "$$\n",
        "\n",
        "Thatâ€™s the number the Lasso algorithm tries to **minimize**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ”„ What happens when we change weights?\n",
        "\n",
        "Now try:\n",
        "\n",
        "* $w_1 = 3$, $w_2 = 1$, $b = 3$\n",
        "\n",
        "Then:\n",
        "\n",
        "$$\n",
        "\\hat{y} = 3Ã—1 + 1Ã—1 + 3 = 7 \\quad \\text{(same prediction)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Error} = (10 - 7)^2 = 9\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Penalty} = |3| + |1| = 4\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Lasso Loss} = 9 + 4 = 13 âœ… (Better!)\n",
        "$$\n",
        "\n",
        "Even though the prediction error is the same (9), the second set of weights gives a **lower total loss**, because the weights are **smaller** â€” **Lasso prefers smaller weights**.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§  Key Insight:\n",
        "\n",
        "> **Lasso \"punishes\" large weights** by adding their absolute values to the loss.\n",
        "> The model **adjusts weights to be smaller or even 0**, so the **total cost becomes lower**.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wu4VJUvI3pOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## âœ… GENERALIZED PROCESS (for both Linear & Lasso Regression):\n",
        "\n",
        "### ðŸ” Step-by-Step:\n",
        "\n",
        "1. **Initialize** weights $w_1, w_2, ..., w_n$ and intercept $b$\n",
        "\n",
        "2. **Make Predictions**\n",
        "\n",
        "   $$\n",
        "   \\hat{y} = w_1 x_1 + w_2 x_2 + \\dots + w_n x_n + b\n",
        "   $$\n",
        "\n",
        "3. **Calculate Error**\n",
        "   Usually **Mean Squared Error (MSE)**:\n",
        "\n",
        "   $$\n",
        "   \\text{MSE} = \\frac{1}{m} \\sum (y - \\hat{y})^2\n",
        "   $$\n",
        "\n",
        "4. **(If Lasso) Add Penalty**\n",
        "\n",
        "   $$\n",
        "   \\text{Lasso Loss} = \\text{MSE} + \\alpha \\sum |w_i|\n",
        "   $$\n",
        "\n",
        "5. **Adjust Weights and Bias**\n",
        "   Change weights **to reduce the total loss** (error + penalty in case of Lasso)\n",
        "\n",
        "6. **Repeat Steps 2â€“5**\n",
        "   Until the **error is minimized** (or until improvement is very small)\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Š Key Difference in Step 4:\n",
        "\n",
        "| Type                  | Whatâ€™s minimized?                         |\n",
        "| --------------------- | ----------------------------------------- |\n",
        "| **Linear Regression** | Just prediction error (MSE)               |\n",
        "| **Lasso Regression**  | Prediction error **+** penalty on weights |\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ So in Simple Words:\n",
        "\n",
        "> Yes â€” in both linear and lasso, the model **guesses weights**, **checks how bad the error is**, and **keeps adjusting them** to make the **total error as small as possible**.\n",
        "> Lasso adds **extra pressure to keep weights small or zero**.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZZDh7oqd6VCg"
      }
    }
  ]
}