{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **t-SNE (t-distributed Stochastic Neighbor Embedding)**"
      ],
      "metadata": {
        "id": "D5MrCSF9Dr7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 📌 1. Technical Introduction\n",
        "\n",
        "### 🧭 Where It Fits:\n",
        "\n",
        "* Part of **Unsupervised Learning**, under **Dimensionality Reduction**\n",
        "* Specifically designed for **visualizing high-dimensional data in 2D or 3D**\n",
        "\n",
        "### 🛠 How It Works Conceptually:\n",
        "\n",
        "* t-SNE maps high-dimensional points into lower dimensions (2D/3D) while preserving **local relationships**.\n",
        "* It tries to place **similar points close together** and **dissimilar points far apart**.\n",
        "\n",
        "### Key Terms:\n",
        "\n",
        "* **High-Dimensional Space**: Original data with many features\n",
        "* **Low-Dimensional Space**: Compressed 2D/3D version for visualization\n",
        "* **Perplexity**: Balances local vs. global structure; like the number of neighbors each point considers\n",
        "* **KL Divergence**: A way to measure how different two distributions are\n",
        "\n",
        "---\n",
        "\n",
        "## 🧸 2. Simplified Explanation\n",
        "\n",
        "Imagine compressing a large **world map into a small sheet**, where:\n",
        "\n",
        "* Nearby cities still stay close\n",
        "* Far-away cities remain distant (mostly)\n",
        "\n",
        "t-SNE is like a **smart map-maker**:\n",
        "\n",
        "> It keeps nearby points **visually close**, so you can **see the data’s structure** — like clusters — even if the original data had 100+ dimensions.\n",
        "\n",
        "---\n",
        "\n",
        "## 📕 3. Definition\n",
        "\n",
        "> **t-SNE** is a non-linear, unsupervised dimensionality reduction technique that transforms high-dimensional data into a lower-dimensional space while preserving local neighborhood structure using probability distributions and minimizing divergence between them.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 4. Simple Analogy\n",
        "\n",
        "🧩 **Friend Groups Analogy**:\n",
        "You’re trying to draw a seating chart where:\n",
        "\n",
        "* Best friends sit together\n",
        "* Strangers sit apart\n",
        "\n",
        "t-SNE does this by comparing who’s “close” in the original world and arranges them similarly in 2D — so **natural groups form** visually.\n",
        "\n",
        "---\n",
        "\n",
        "## 🚗 5. Examples\n",
        "\n",
        "### 🚘 Automotive:\n",
        "\n",
        "* **Cluster driving patterns** using high-dimensional sensor data\n",
        "* **Visualize health of ECUs** or battery packs by reducing diagnostic features\n",
        "* Compare **vehicle usage clusters** in fleet analytics\n",
        "\n",
        "### 🌍 General:\n",
        "\n",
        "* Visualizing high-dimensional **image embeddings**\n",
        "* Clustering **gene expression profiles**\n",
        "* Understanding **word embeddings** (like Word2Vec)\n",
        "\n",
        "---\n",
        "\n",
        "## 📐 6. Mathematical Equations\n",
        "\n",
        "### Step 1: Compute Similarities in High-D Space\n",
        "\n",
        "For each pair of points $x_i, x_j$, compute:\n",
        "\n",
        "$$\n",
        "p_{j|i} = \\frac{\\exp(-\\|x_i - x_j\\|^2 / 2\\sigma_i^2)}{\\sum_{k \\neq i} \\exp(-\\|x_i - x_k\\|^2 / 2\\sigma_i^2)}\n",
        "$$\n",
        "\n",
        "Then:\n",
        "\n",
        "$$\n",
        "p_{ij} = \\frac{p_{j|i} + p_{i|j}}{2n}\n",
        "$$\n",
        "\n",
        "### Step 2: Compute Similarities in Low-D Space\n",
        "\n",
        "$$\n",
        "q_{ij} = \\frac{(1 + \\|y_i - y_j\\|^2)^{-1}}{\\sum_{k \\neq l} (1 + \\|y_k - y_l\\|^2)^{-1}}\n",
        "$$\n",
        "\n",
        "### Step 3: Minimize KL Divergence\n",
        "\n",
        "Cost function:\n",
        "\n",
        "$$\n",
        "KL(P \\parallel Q) = \\sum_{i \\neq j} p_{ij} \\log \\frac{p_{ij}}{q_{ij}}\n",
        "$$\n",
        "\n",
        "This is minimized using **gradient descent**.\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 7. Important Information\n",
        "\n",
        "* t-SNE focuses on **local structure**, not global\n",
        "* **Doesn’t preserve distances or scales**\n",
        "* **Non-deterministic** — results can change each time unless you set a `random_state`\n",
        "* You should **standardize/normalize** data before applying t-SNE\n",
        "\n",
        "---\n",
        "\n",
        "## 🔁 8. Comparison with Similar Topics\n",
        "\n",
        "| Feature      | PCA             | t-SNE                | UMAP                |\n",
        "| ------------ | --------------- | -------------------- | ------------------- |\n",
        "| Type         | Linear          | Non-linear           | Non-linear          |\n",
        "| Preserves    | Global variance | Local similarity     | Local + some global |\n",
        "| Speed        | ⚡ Fast          | 🐢 Slow              | 🚀 Fast             |\n",
        "| Reproducible | ✅ Yes           | ❌ No (unless seeded) | ✅ Yes (mostly)      |\n",
        "| Useful for   | Preprocessing   | Visualization        | Visualization + ML  |\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ 9. Advantages and Disadvantages\n",
        "\n",
        "### ✅ Advantages:\n",
        "\n",
        "* Creates **beautiful 2D/3D plots**\n",
        "* Helps visually discover **clusters**\n",
        "* Works well even when **data is not linearly separable**\n",
        "\n",
        "### ❌ Disadvantages:\n",
        "\n",
        "* Slow on large datasets\n",
        "* Doesn’t preserve true distances or densities\n",
        "* Hard to tune parameters (especially `perplexity`)\n",
        "\n",
        "---\n",
        "\n",
        "## ⚠️ 10. Things to Watch Out For\n",
        "\n",
        "* Always **normalize** data before t-SNE\n",
        "* Results may vary — use `random_state` for reproducibility\n",
        "* **Choose perplexity wisely** (typically between 5–50)\n",
        "* **Not suitable** for downstream tasks (like feeding into another model)\n",
        "\n",
        "---\n",
        "\n",
        "## 💡 11. Other Critical Insights\n",
        "\n",
        "* You can use **PCA before t-SNE** to speed it up\n",
        "* t-SNE is great for **checking clustering quality** (e.g., after K-Means)\n",
        "* Use **UMAP** if you want better global structure and faster performance\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "0P6kKFj8DvDc"
      }
    }
  ]
}